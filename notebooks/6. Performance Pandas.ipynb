{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Performance Pandas\n",
    "\n",
    "![](http://d.pr/i/cLFsU9+)\n",
    "\n",
    "Python is slower than compiled languages for a variety of reasons:\n",
    "\n",
    "### Python is Dynamically Typed rather than Statically Typed.\n",
    "\n",
    "What this means is that at the time the program executes, the interpreter doesn't know the type of the variables that are defined. For example, the difference between a C variable and a Python variable is summarized by this diagram:\n",
    "\n",
    "![](images/cint_vs_pyint.png)\n",
    "\n",
    "For a variable in C, the compiler knows the type by its very definition. For a variable in Python, all you know at the time the program executes is that it's some sort of Python object.\n",
    "\n",
    "So if you write the following in C:\n",
    "\n",
    "```C\n",
    "int a = 1;\n",
    "int b = 2;\n",
    "int c = a + b;\n",
    "```\n",
    "\n",
    "the C compiler knows from the start that a and b are integers: they simply can't be anything else! With this knowledge, it can call the routine which adds two integers, returning another integer which is just a simple value in memory. As a rough schematic, the sequence of events looks like this:\n",
    "\n",
    "**C Addition**\n",
    "\n",
    "1. Assign <int> 1 to a\n",
    "2. Assign <int> 2 to b\n",
    "3. call binary_add<int, int>(a, b)\n",
    "4. Assign the result to c\n",
    "\n",
    "The equivalent code in Python looks like this:\n",
    "\n",
    "```python\n",
    "a = 1\n",
    "b = 2\n",
    "c = a + b\n",
    "```\n",
    "\n",
    "here the interpreter knows only that 1 and 2 are objects, but not what type of object they are. So the The interpreter must inspect PyObject_HEAD for each variable to find the type information, and then call the appropriate summation routine for the two types. Finally it must create and initialize a new Python object to hold the return value. The sequence of events looks roughly like this:\n",
    "\n",
    "**Python Addition**\n",
    "\n",
    "1. Assign 1 to a\n",
    "    - Set a->PyObject_HEAD->typecode to integer\n",
    "    - Set a->val = 1\n",
    "2. Assign 2 to b\n",
    "    - Set b->PyObject_HEAD->typecode to integer\n",
    "    - Set b->val = 2\n",
    "3. call binary_add(a, b)\n",
    "    - find typecode in a->PyObject_HEAD\n",
    "    - a is an integer; value is a->val\n",
    "    - find typecode in b->PyObject_HEAD\n",
    "    - b is an integer; value is b->val\n",
    "    - call binary_add<int, int>(a->val, b->val)\n",
    "    - result of this is result, and is an integer.\n",
    "4. Create a Python object c\n",
    "    - set c->PyObject_HEAD->typecode to integer\n",
    "    - set c->val to result\n",
    "\n",
    "The dynamic typing means that there are a lot more steps involved with any operation. This is a primary reason that Python is slow compared to C for operations on numerical data.\n",
    "\n",
    "### Python is interpreted rather than compiled.\n",
    "\n",
    "We saw above one difference between interpreted and compiled code. A smart compiler can look ahead and optimize for repeated or unneeded operations, which can result in speed-ups. Compiler optimization is its own beast, and I'm personally not qualified to say much about it, so I'll stop there. \n",
    "\n",
    "### Python's object model can lead to inefficient memory access\n",
    "\n",
    "We saw above the extra type info layer when moving from a C integer to a Python integer. Now imagine you have many such integers and want to do some sort of batch operation on them. In Python you might use the standard List object, while in C you would likely use some sort of buffer-based array.\n",
    "\n",
    "A NumPy array in its simplest form is a Python object build around a C array. That is, it has a pointer to a contiguous data buffer of values. A Python list, on the other hand, has a pointer to a contiguous buffer of pointers, each of which points to a Python object which in turn has references to its data (in this case, integers). This is a schematic of what the two might look like:\n",
    "\n",
    "![](images/array_vs_list.png)\n",
    "\n",
    "You can see that if you're doing some operation which steps through data in sequence, the numpy layout will be much more efficient than the Python layout, both in the cost of storage and the cost of access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up statistical computations in Python\n",
    "\n",
    "In the age of \"big data\" and sophisitcated Bayesian and statistical learning algorithms, many are interested in optimizing the performance of the high-level languages that we use to analyse data.\n",
    "\n",
    "[NumPy](http://numpy.scipy.org/) gets us part of the way there on Python:\n",
    "\n",
    "* Storage of multidimensional data\n",
    "* Efficient data access\n",
    "* Efficient in-memory storage\n",
    "* Fast methods and functions for data manipulation\n",
    "\n",
    "Ffor many applications, this is sufficient to drastically improve performance. However, there is plenty of scope for improving Python's performance in situations where speed matters.\n",
    "\n",
    "Pure Python and Python with NumPy are not particularly fast. Below are some recent performance benchmarks comparing several computing languages (taken directly from the [Julia website](http://julialang.org)):\n",
    "\n",
    "\n",
    "<div class=\"figure\">\n",
    "<table class=\"benchmarks\">\n",
    "<colgroup>\n",
    "<col class=\"name\" />\n",
    "<col class=\"relative\" span=\"11\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr><td></td><th class=\"system\">Fortran</th><th class=\"system\">Julia</th><th class=\"system\">Python</th><th class=\"system\">R</th><th class=\"system\">Matlab</th><th class=\"system\">Octave</th><th class=\"system\">Mathematica</th><th class=\"system\">JavaScript</th><th class=\"system\">Go</th><th class=\"system\">LuaJIT</th><th class=\"system\">Java</th></tr>\n",
    "<tr><td></td><td class=\"version\">gcc 5.1.1\n",
    "</td><td class=\"version\">0.4.0\n",
    "</td><td class=\"version\">3.4.3\n",
    "</td><td class=\"version\">3.2.2\n",
    "</td><td class=\"version\">R2015b\n",
    "</td><td class=\"version\">4.0.0\n",
    "</td><td class=\"version\">10.2.0\n",
    "</td><td class=\"version\">V8 3.28.71.19\n",
    "</td><td class=\"version\">go1.5\n",
    "</td><td class=\"version\">gsl-shell 2.3.1\n",
    "</td><td class=\"version\">1.8.0_45\n",
    "</td></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><th>fib</th><td class=\"data\">0.70</td><td class=\"data\">2.11</td><td class=\"data\">77.76</td><td class=\"data\">533.52</td><td class=\"data\">26.89</td><td class=\"data\">9324.35</td><td class=\"data\">118.53</td><td class=\"data\">3.36</td><td class=\"data\">1.86</td><td class=\"data\">1.71</td><td class=\"data\">1.21</td></tr>\n",
    "<tr><th>parse_int</th><td class=\"data\">5.05</td><td class=\"data\">1.45</td><td class=\"data\">17.02</td><td class=\"data\">45.73</td><td class=\"data\">802.52</td><td class=\"data\">9581.44</td><td class=\"data\">15.02</td><td class=\"data\">6.06</td><td class=\"data\">1.20</td><td class=\"data\">5.77</td><td class=\"data\">3.35</td></tr>\n",
    "<tr><th>quicksort</th><td class=\"data\">1.31</td><td class=\"data\">1.15</td><td class=\"data\">32.89</td><td class=\"data\">264.54</td><td class=\"data\">4.92</td><td class=\"data\">1866.01</td><td class=\"data\">43.23</td><td class=\"data\">2.70</td><td class=\"data\">1.29</td><td class=\"data\">2.03</td><td class=\"data\">2.60</td></tr>\n",
    "<tr><th>mandel</th><td class=\"data\">0.81</td><td class=\"data\">0.79</td><td class=\"data\">15.32</td><td class=\"data\">53.16</td><td class=\"data\">7.58</td><td class=\"data\">451.81</td><td class=\"data\">5.13</td><td class=\"data\">0.66</td><td class=\"data\">1.11</td><td class=\"data\">0.67</td><td class=\"data\">1.35</td></tr>\n",
    "<tr><th>pi_sum</th><td class=\"data\">1.00</td><td class=\"data\">1.00</td><td class=\"data\">21.99</td><td class=\"data\">9.56</td><td class=\"data\">1.00</td><td class=\"data\">299.31</td><td class=\"data\">1.69</td><td class=\"data\">1.01</td><td class=\"data\">1.00</td><td class=\"data\">1.00</td><td class=\"data\">1.00</td></tr>\n",
    "<tr><th>rand_mat_stat</th><td class=\"data\">1.45</td><td class=\"data\">1.66</td><td class=\"data\">17.93</td><td class=\"data\">14.56</td><td class=\"data\">14.52</td><td class=\"data\">30.93</td><td class=\"data\">5.95</td><td class=\"data\">2.30</td><td class=\"data\">2.96</td><td class=\"data\">3.27</td><td class=\"data\">3.92</td></tr>\n",
    "<tr><th>rand_mat_mul</th><td class=\"data\">3.48</td><td class=\"data\">1.02</td><td class=\"data\">1.14</td><td class=\"data\">1.57</td><td class=\"data\">1.12</td><td class=\"data\">1.12</td><td class=\"data\">1.30</td><td class=\"data\">15.07</td><td class=\"data\">1.42</td><td class=\"data\">1.16</td><td class=\"data\">2.36</td></tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<p class=\"caption\"><b>Figure:</b>\n",
    "benchmark times relative to C (smaller is better, C performance = 1.0).\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "So, while fast relative to some scientific compution choices (*e.g.* R, Matlab), Python sometimes needs to be tweaked in order to make it a competitive choice for implementing modern statistical methods. We will cover two approachable ways of improving the performance of Python.\n",
    "\n",
    "\n",
    "## Profiling\n",
    "\n",
    "Before you barrel ahead and prematurely optimize your Python code, it is important to understand **why** and **where** your code is slow. This is achieved by systematically accounting for the resources that your code is using, such as memory, CPU time or data transfer. This process is broadly referred to as ***Profiling***, and it allows you to identify where the performance bottlenecks in your code lie.\n",
    "\n",
    "Here, we will concentrate on optimizing performance for **CPU-bound** problems.\n",
    "\n",
    "There are a number of tools to help you profile your code.\n",
    "\n",
    "### `time`\n",
    "\n",
    "For those of you on UNIX platforms, the built-in utility `time` can be used to assess how long your code takes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!time python ../examples/abc.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from `time` can be interpreted as:\n",
    "\n",
    "* `real`: elapsed (wall) time\n",
    "* `user`: time spent in your code\n",
    "* `sys`: time spent in system (kernel) functions\n",
    "\n",
    "The last 2 quantities account for the cycles used by your program. The remaining `real` time is often due to waiting for information either from disk or a network connection (I/O).\n",
    "\n",
    "Python also has a `time` module (and function) that is more rudimentary; it simply returns the time, in seconds from the Epoch (1/1/1970)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this for profiling by differencing the times before and after running some code of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "start_time = time.time()\n",
    "np.product(range(1, 100000))\n",
    "end_time = time.time()\n",
    "\n",
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however that it does not provide a breakdown of where the code spends its time.\n",
    "\n",
    "### IPython magic: `%timeit`, `%run` and `%prun`\n",
    "\n",
    "IPython has three built-in \"magic\" functions that are useful for profiling your code. \n",
    "\n",
    "The `%timeit` magic executes a Python statement or expressions in a loop to see how long we expect it to take for any given call. Additionally, it repeats the loop a certain number of times, and returns the best result.\n",
    "\n",
    "As an example, consider a Python implementation of the **trapezoidal rule**, a method from numerical analysis for approximating a definite integral. Specifically, it allows us to approximate:\n",
    "\n",
    "$$\\int_a^b f(x) dx$$\n",
    "\n",
    "using the approximation:\n",
    "\n",
    "$$\\int_a^b f(x) dx \\approx (b-a) \\frac{f(b) + f(a)}{2}$$\n",
    "\n",
    "Rather than use a single interval for this estimate, we break the interval down into $n$ subintervals, to obtain a more accurate approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "      \n",
    "def trapez(a, b, n):\n",
    "    h = (b-a)/float(n) \n",
    "    sumy = 0\n",
    "    x=a\n",
    "    \n",
    "    for i in range(n):\n",
    "        x += h\n",
    "        sumy += f(x)\n",
    "    sumy += 0.5*(f(a) + f(b))\n",
    "    return sumy*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trapez(1, 5, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that this works, we can compare this to the symbolic solution, using Sympy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sympy as sym\n",
    "\n",
    "xs = sym.symbols('xs')\n",
    "\n",
    "fx = 2*xs*xs + 3*xs + 1\n",
    "\n",
    "ifx = sym.integrate(fx, (xs, 1, 5))\n",
    "ifx.evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit trapez(1, 5, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%timeit` tries to pick suitable values for the number of loops and repeats; these values can be overriden by specifying `-n` and `-r` values, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling results can be saved to a variable by calling the %timeit magic with the `-o` flag:\n",
    "\n",
    "    %timeit -o <expression>\n",
    "\n",
    "This returns a `TimeitResult` object, which includes information about the %timeit run as attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trapez_prof = %timeit -o trapez(1, 5, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trapez_prof.best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%run` command with a `-p` option allows you to run complete programs under the control of the Python profiler. It writes the output to the help pane, which opens at the bottom of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code redirects pager output to a regular cell\n",
    "from IPython.core import page\n",
    "page.page = print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -p ../examples/abc.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The profiling information includes the following information:\n",
    "\n",
    "* `ncalls`: number of calls to function\n",
    "* `tottime`: total time spent in the given function (excluding time in calls to sub-functions)\n",
    "* `percall`: time per call\n",
    "* `cumtime`: cumulative time spent in this and all subfunctions \n",
    "\n",
    "We can see that most of the time in this example is spent inside of core NumPy functions and methods.\n",
    "\n",
    "The `%prun` command does a similar job for single Python expressions (like function calls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun trapez(2, 6, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For even more fine-grained profiling information, we can use a line profiler to see how long it takes each line of a function to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pprofile ../examples/bisection.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output makes it clear that the biggest cost is in the repeated calling of the function $f$ for which the root is being found. If we could improve the speed of this function, it would be the easiest single way of improving the performance of the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up Pandas by Being Idiomatic\n",
    "\n",
    "When you have decided that your code is unacceptably slow, and have gone through the process of profiling to see if and where your program is experiencing a bottleneck, it can be easy to jump ahead and try speeding it up using external tools. There are several packages that will certainly improve Python's performance (and we will introduce some of them later), but the first place to look for better performance is in **refactoring** your implementation of whichever algorithm you happen to be using. \n",
    "\n",
    "Effective pandas programming (and Python, in general) involves applying particular **idioms** effectively; these are idiosyncratic expressions that may only exist in Python or pandas, but when used appropriately they can make your code more readable, faster, or both. You have seen some of these already -- for example, the **list comprehension** as a means for succinctly implementing a `for` loop.\n",
    "\n",
    "### Comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_math(x):\n",
    "    return 3 + x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "squares = []\n",
    "for i in range(1000):\n",
    "    squares.append(do_math(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit squares = [do_math(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, not only is the list comprehension easier to write and read, it is also slightly faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String concatenation\n",
    "\n",
    "Just as you should avoid growing lists or arrays by concatenation or appending, iterating over strings and concatenating them manually is very inefficient. For example, let's say we want to concatente a list of strings into a single string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = [\"Six\",\n",
    "\"days\",\n",
    "\"in\",\n",
    "\"to\",\n",
    "\"what\",\n",
    "\"should\",\n",
    "\"be\",\n",
    "\"a\",\n",
    "\"greatest\",\n",
    "\"two\",\n",
    "\"months\",\n",
    "\"of\",\n",
    "\"my\",\n",
    "\"life\",\n",
    "\"and\",\n",
    "\"itâ€™s\",\n",
    "\"turned\",\n",
    "\"in\",\n",
    "\"to\",\n",
    "\"a\",\n",
    "\"nightmare\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might be tempted to code the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sentence = \"\"\n",
    "for word in words:\n",
    "    sentence += word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is inefficient; since strings is immutable in Python, every `+` operation involves creating a new string and copying the old content. Instead, we can use the string method `join`, which is not only faster, but more flexible. Here, we would like to separate the words by spaces, which is easily done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames\n",
    "\n",
    "An often-seen pattern in pandas is the combining of several imported datasets into a single DataFrame. Larger datasets are frequently stored in chunks on disk (*e.g.* multiple years of meteorological data).\n",
    "\n",
    "One might instinctually want to instantiate an empty DataFrame of the appropriate dimension (in terms of columns), and iteratively add data to it. For example, consider the ebola data that we explored in a previous section. The data from Liberia consists of a directory of CSV files with identical structure.\n",
    "\n",
    "We can use the IPython \"bang\" syntax to retrieve the list of files from this directory and assign them to a variable as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/ebola/liberia_data/'\n",
    "data_files = !ls $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the column names for each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['Date','Variable','National','Bomi County','Bong County','Grand Kru',\n",
    "           'Lofa County','Margibi County','Maryland County','Montserrado County',\n",
    "           'Nimba County','River Gee County','RiverCess County','Sinoe County']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under this strategy, we create an empty DataFrame and loop over the list of files, appending the contents of the file to the DataFrame. You might already be able to guess that this is not an efficient approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "liberia_data = pd.DataFrame(columns=columns)\n",
    "for f in data_files:\n",
    "    chunk = pd.read_csv(DATA_DIR+f)\n",
    "    liberia_data = liberia_data.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liberia_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "liberia_data = pd.concat([pd.read_csv(DATA_DIR+f) for f in data_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vessels = pd.read_csv(\"../data/AIS/vessel_information.csv\", index_col='mmsi')\n",
    "segments = pd.read_csv(\"../data/AIS/transit_segments.csv\")\n",
    "segments_merged = pd.merge(vessels, segments, left_index=True, right_on='mmsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top(df, column, n=5):\n",
    "    return df.sort_values(by=column, ascending=False)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segments_by_vessel = segments_merged.groupby('mmsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit -n 3 segments_by_vessel.apply(top, column='seg_length', n=3)[['names', 'seg_length']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit -n 3 segments_by_vessel.seg_length.nlargest(3).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "\n",
    "General advice for gaining speed and efficiency with pandas is to use appropriate data types within columns of a DataFrame or in a Series. When importing data, columns can end up with an `object` data type, which is very general, but also quite inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vessels.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`object` data are manipulated using pure Python code, whereas various numneric types run using faster C code. With character data you are generally stuck with an `object` data type, though there is one exeption: **categorical** data.\n",
    "\n",
    "Categorical data are strings with relatively few distict values relative to the number of elements in the data (also known as having loe cardinality). In pandas, you may want to represent such data using the `categorical` data type.\n",
    "\n",
    "For example, consider the `flag` column in the vessel dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vessels.flag.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vessels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vessels['flag_cat'] = vessels.flag.astype('category')\n",
    "vessels.flag_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories are represented internally by unique integers, which is far more compact to store in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vessels.flag_cat.memory_usage(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vessels.flag.memory_usage(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only are `categorical` variables more memory efficient than leaving them as `object` types, but they can appreciably speed up computations that use them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segments_merged['flag_cat'] = segments_merged.flag.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit segments_merged.groupby('flag').seg_length.nlargest(10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit segments_merged.groupby('flag_cat').seg_length.nlargest(10).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is an appreciable speedup obtained simply by using a more appropriate data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast array expression evaluation with `eval`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the performance of processors has outpaced that of memory in the past several decades, the CPU spends a lot of time waiting for memory to give it computations; this is the ***processor-memory performance gap***.\n",
    "\n",
    "![performance gap](http://www.techdesignforums.com/practice/files/2013/02/tdf-snps-ARMcc-feb13-fig1lg.jpg)\n",
    "(graph courtesy http://www.techdesignforums.com)\n",
    "\n",
    "CPU caches are often used to make up for this difference. CPU caches are more effective when the data are optimally located in memory to take advantage of cache performance. `numexpr` does this by moving contiguous blocks of data from memory to the CPU cache, reusing them as much as possible within the cache to more quickly give the CPU access to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`numexpr`](http://code.google.com/p/numexpr/) package allows array expressions to be evaluated far faster that what can be achieved in Python using Numpy arrays. `numexpr` parses a string expression and optimizes and compiles the code on the fly, using a virtual machine that includes a [Just-in-time (JIT) compiler](http://en.wikipedia.org/wiki/Just-in-time_compilation). \n",
    "\n",
    "In addition, `numexpr` offers direct support for parallel multi-threaded computations, since Python's global interpreter lock is bypassed.\n",
    "\n",
    "> Python's global interpreter lock (GIL) ensures that only one thread runs in the interpreter at once. This simplifies many of the low-level activities, such as memory management, and allows for co-operative multi-tasking. But, since the currently-running thread holds onto the interpreter, it makes multi-core parallelization difficult.\n",
    "\n",
    "Part the reason Python can be slow for array calculations is that it creates temporary arrays to store intermediate results from array element calculations, which wastes memory and cache. `numexpr` handles such calculations in manageable chunks, which accellerates computation.\n",
    "\n",
    "The speedup over NumPy by using `numexpr` can be as high as 20x, but is typically in the range of 2-4x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas  `eval()`\n",
    "\n",
    "The `eval` function in pandas implements `numexpr` for as an engine for expression evaluation with `Series` and `DataFrame` objects.\n",
    "\n",
    "`eval` provides better efficiency for evaluation of large datasets, whereby large expressions are evaluated simultaneously by the `numexpr` engine.\n",
    "\n",
    "The operations supported include:\n",
    "\n",
    "- Arithmetic operations except for the left shift (<<) and right shift (>>) operators\n",
    "    - `df + 2 * pi / s ** 4 % 42 - the_golden_ratio`\n",
    "- Comparison operations, including chained comparisons\n",
    "    - `2 < df < df2`\n",
    "- Boolean operations\n",
    "    - `df < df2 and df3 < df4 or not df_bool`\n",
    "- `list` and `tuple` literals\n",
    "    - `[1, 2] or (1, 2)`\n",
    "- Attribute access\n",
    "    - `df.a`\n",
    "- Subscript expressions\n",
    "    - `df[0]`\n",
    "- Math functions: `sin, cos, exp, log, expm1, log1p, sqrt, sinh, cosh, tanh, arcsin, arccos, arctan, arccosh, arcsinh, arctanh, abs` and `arctan2`\n",
    "\n",
    "Most complex Python syntax is **not** supported, including flow control statements, funciton calls (except math), generator expressions, dictionaries and sets, and lambda functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NROWS, NCOLS = 10000, 1000\n",
    "\n",
    "df1, df2, df3 = [pd.DataFrame(np.random.randn(NROWS, NCOLS)) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df1 + df2 + df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit pd.eval('df1 + df2 + df3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a Python backend to `eval` rather than `numexp`, but it is not generally useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit pd.eval('df1 + df2 + df3', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do boolean operations now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit (df1 > df2) & (df2 > df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit pd.eval('(df1 > df2) & (df2 > df3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid expressions can also be evaluated using the `DataFrame.eval` method. This allows you to avoid prefixing dataframe names to the columns you want to operate on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.poisson(lam=10, size=(1000000, 2)), columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.eval('x + y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.normal(10, scale=5, size=(1000000, 2)), columns=['x', 'y'])\n",
    "\n",
    "df.eval('1.5*x + 0.25*x**2 - 3.4*y + 0.75*y**2 - 10').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the `eval` method to perform assignment of columns within an expression, provided that the assignment target is a valid Python identifier.\n",
    "\n",
    "This is one of the rare cases where `inplace=True` is not a bad idea (in fact, its the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.eval('z = x<10', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple assignment can be achieved by using multi-line strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.eval('''z = x<10\n",
    "w = (x**2 + y**2)**0.5''', inplace=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local variables can be accessed using the `@` identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "const = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.eval('x * @const').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this does not work in the `eval` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.eval('df.x + @const')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the DataFrames and/or expression, the bigger gain in performance you will see.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Use both `eval` and Python to operate on data frames of different size, and report the performance of each.\n",
    "\n",
    "- 0 to 10 million rows in increments of 1 million\n",
    "- 0 to 50,000 rows in increments of 1000\n",
    "\n",
    "Save the timings to a DataFrame and plot the relative performance in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython\n",
    "\n",
    "Python developers typically solve performance constraints by building Python extensions by wrapping code written in other languages (for example, SciPy contains more lines of C/C++/Fortran than Python). However, programming with the Python/C API is not straightforward for most users.\n",
    "\n",
    "Cython is a language that allows Python programmers to write fast code without having to write C/C++/Fortran directly. It looks much like Python code, but with type declarations. Cython code is translated it to C (or C++ or others), which is then compiled to create a Python extension that we can import and use. \n",
    "\n",
    "Using Cython, we can achieve speedups of several orders of magnitude, often *faster than hand-coded C code*. In addtion, Cython is compatible with core scientific programming tools like NumPy and IPython.\n",
    "\n",
    "Cython has built-in support for multicore processing.\n",
    "\n",
    "Cython is used to varying degrees by other packages in the Python scientific stack, such as sympy, scikit-learn, SciPy and pandas.\n",
    "\n",
    "### Example: Numerical integration\n",
    "\n",
    "Recall from above the function `trapez` for performing numerical integration using the trapezoidal rule. \n",
    "\n",
    "```python\n",
    "def f(x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "      \n",
    "def trapez(a, b, n):\n",
    "    h = (b-a)/float(n) \n",
    "    sumy = 0\n",
    "    x=a\n",
    "    \n",
    "    for i in range(n):\n",
    "        x += h\n",
    "        sumy += f(x)\n",
    "    sumy += 0.5*(f(a) + f(b))\n",
    "    return sumy*h\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's `apply` this function to a DataFrame of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': np.random.randn(1000),\n",
    "                    'b': np.random.randn(1000),\n",
    "                    'N': np.random.randint(100, 1000, (1000)),\n",
    "                    'x': 'x'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: trapez(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's profile this to see where the code is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun -l 4 df.apply(lambda x: trapez(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the time is spent inside either of our two functions, so it is worthwhile to convert them to Cython.\n",
    "\n",
    "Perhaps the easiest way to use Cython, is via the IPython cython magic, which allows us to run Cython interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simply apply this magic to the functions as written, without changing anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def f(x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "def trapez2(a, b, n):\n",
    "    h = (b-a)/float(n) \n",
    "    sumy = 0\n",
    "    x=a\n",
    "    for i in range(n):\n",
    "        x += h\n",
    "        sumy += f(x)\n",
    "    sumy += 0.5*(f(a) + f(b))\n",
    "    return sumy*h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cython magic is doing a lot of work for you: it compiles the code into an extension module, and loads it into the notebook. This allows us to ignore all of the compilation details of building Cython extensions. \n",
    "\n",
    "If we run `trapez2`, we can see a reasonable speedup simply by compiling it, unchanged, using Cython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: trapez2(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, several things are happening in order to deliver this improved performance. The Cython source code is translated into C source code by `cython`. Then, this C source is compiled, using the appropriate compiler, flags and associated library files (if any), into a Python extension. This extension is then loaded by IPython into the current session.\n",
    "\n",
    "![cython flow](images/cython.png)\n",
    "\n",
    "C extensions can also be compiled manually, using a setup file. Here is an example for an extension called `dist` within a package called `probability`:\n",
    "\n",
    "```python\n",
    "from distutils.core import setup\n",
    "from distutils.extension import Extension\n",
    "from Cython.Distutils import build_ext\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "setup(\n",
    "    cmdclass = {'build_ext': build_ext},\n",
    "    ext_modules = [Extension(\"dist\", [\"probability/src/dist.pyx\"], include_dirs=[np.get_include()])]\n",
    ")\n",
    "```\n",
    "    \n",
    "It mainly uses machinery from a core Python package `distutils` that manages the build process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a closer look at where Cython is improving our unchanged Python code, we can add an `--annotate` flag to the `%%cython` magic declaration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "def f(x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "      \n",
    "def trapez2(a, b, n):\n",
    "    h = (b-a)/float(n) \n",
    "    sumy = 0\n",
    "    x=a\n",
    "    for i in range(n):\n",
    "        x += h\n",
    "        sumy += f(x)\n",
    "    sumy += 0.5*(f(a) + f(b))\n",
    "    return sumy*h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, the line color indicates the \"typedness\" of the extension, where yellower lines are closer to Python, and therefore require calls to the Python C API, while whiter lines indicate code that is closer to pure C, hence requiring few, if any, Python API calls.\n",
    "\n",
    "If you click on a line, it unravels to show you the C code that results from the call to `cython`.\n",
    "\n",
    "The goal in speeding up code with Cython is to turn as many lines to white as we can. The easiest way to do this is to add type declarations to the Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "# Add type to argument\n",
    "def ff(double x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "# Add types to arguments\n",
    "def trapez3(double a, double b, int n):\n",
    "    # Declare types of variables\n",
    "    cdef double h, x, sumy\n",
    "    cdef int i\n",
    "    h = (b-a)/float(n) \n",
    "    sumy = 0\n",
    "    x=a\n",
    "    for i in range(n):\n",
    "        x += h\n",
    "        sumy += ff(x)\n",
    "    sumy += 0.5*(ff(a) + ff(b))\n",
    "    return sumy*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: trapez3(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a considerable speedup. Let's have a look at the profiler report for the new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun -l 4 df.apply(lambda x: trapez3(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we might try is to *inline* the polynomial function. By inlining, we mean that we ask the compiler to perform an inline expansion of said function; that is, it will insert a copy of the function itself wherever the function is called, instead of calling the function wherever it is defined.\n",
    "\n",
    "We do three things to the specification of `ff`:\n",
    "\n",
    "* change `def` to `cdef`\n",
    "* add a return type to the function\n",
    "* add an `inline` keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "cdef inline double ff(double x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "cpdef trapez4(double a, double b, int n):\n",
    "    cdef double h, x, sumy\n",
    "    cdef int i\n",
    "    h = (b-a)/float(n) \n",
    "    sumy = 0\n",
    "    x=a\n",
    "    for i in range(n):\n",
    "        x += h\n",
    "        sumy += ff(x)\n",
    "    sumy += 0.5*(ff(a) + ff(b))\n",
    "    return sumy*h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cdef` keyword declares a C object. Everything that follows it is therefore specified in terms of C; we are essentially writing C, but using a subset of Python's syntax rules. So, when we are creating a function `cdef ff` it is a C function, and is not available to you in Python.\n",
    "\n",
    "`cpdef` is a hybrid declaration that creates both a C interface and a Python interface to the function.\n",
    "\n",
    "Let's see how this performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: trapez4(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woof! That's a big speedup, and there's not much yellow left in the annotated code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like a very simple way of injecting types into your code with Cython, without modifying any of the code itelf, you can use the `@cython.locals` decorator. Note that you don't get as fast of a speedup as we have just achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "\n",
    "@cython.locals(x=cython.double)\n",
    "def f(x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "     \n",
    "@cython.locals(a=cython.double, b=cython.double, n=cython.int,\n",
    "               h=cython.double, sumy=cython.double, i=cython.int,\n",
    "               x=cython.double, func=cython.double)\n",
    "def trapez5(a, b, n):\n",
    "    h = (b-a)/float(n) \n",
    "    sumy = 0\n",
    "    x=a\n",
    "    \n",
    "    for i in range(n):\n",
    "        x += h\n",
    "        sumy += f(x)\n",
    "    sumy += 0.5*(f(a) + f(b))\n",
    "    return sumy*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: trapez5(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can stand to look at it, you can peek at all the C code that is generated by Cython just to optimize this short function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load ../examples/trapezoid.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `ndarray`\n",
    "\n",
    "If we profile the function now, our functions are not near the top of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun -l 4 df.apply(lambda x: trapez4(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice, however, that `series` is being called a lot. \n",
    "\n",
    "Each row is being turned into a `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "\n",
    "cdef inline double ff(double x) except? -2:\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "cpdef trapez4(double a, double b, int n):\n",
    "    cdef double h, x, sumy\n",
    "    cdef int i\n",
    "    h = (b-a)/float(n) \n",
    "    sumy = 0\n",
    "    x=a\n",
    "    for i in range(n):\n",
    "        x += h\n",
    "        sumy += ff(x)\n",
    "    sumy += 0.5*(ff(a) + ff(b))\n",
    "    return sumy*h\n",
    "\n",
    "cpdef np.ndarray[double] apply_trapez(np.ndarray col_a, np.ndarray col_b, np.ndarray col_n):\n",
    "    assert (col_a.dtype == np.float and col_b.dtype == np.float and col_n.dtype == np.int)\n",
    "    \n",
    "    cdef Py_ssize_t i, n = len(col_n)\n",
    "    assert (len(col_a) == len(col_b) == n)\n",
    "    cdef np.ndarray[double] res = np.empty(n)\n",
    "    \n",
    "    for i in range(len(col_a)):\n",
    "        res[i] = trapez4(col_a[i], col_b[i], col_n[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit apply_trapez(df['a'].values, df['b'].values, df['N'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has cut the execution time yet again. We can see now that there appears to be little remaining to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun -l 4 apply_trapez(df['a'].values, df['b'].values, df['N'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiler directives\n",
    "\n",
    "Here's another simple example, using a function that calculates the Euclidean distance between two arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return np.sqrt(((x - y) ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit euclidean(np.random.randn(10), np.random.randn(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a speedup under Cython, we need to iterate over the elements of each passed array, and aggregate them manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "import cython\n",
    "cimport numpy as np\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def euclidean2(np.ndarray[np.float64_t, ndim=1] x, \n",
    "               np.ndarray[np.float64_t, ndim=1] y):\n",
    "    cdef: \n",
    "        double diff\n",
    "        int i\n",
    "    diff = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        diff += (x[i] - y[i])**2\n",
    "    return sqrt(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit euclidean2(np.random.randn(10), np.random.randn(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decorators for `euclidean2` are **compiler directives** that alter the behavior of Cython code. Setting `boundscheck` to False removes boundary checking for indexing operations, forcing us to ensure that we do not try to index arrays using index vlaues that are out of bounds. When we set `wraparound` to False, Cython will not support negative indexes, as is the case with Python. While these directives may increase the speed of our code, it can be dangerous; if we do not ensure that we index our arrays properly, it may cause segmentation faults or data corruption.\n",
    "\n",
    "The full set of compiler directives are described in the [Cython docs](http://docs.cython.org/src/reference/compilation.html#compiler-directives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same code using lists instead of NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "def euclidean3(list x, list y):\n",
    "    cdef: \n",
    "        double diff\n",
    "        int i\n",
    "    diff = 0\n",
    "    for i in range(len(x)):\n",
    "        diff += (x[i] - y[i])**2\n",
    "    return sqrt(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit euclidean3(np.random.randn(10).tolist(), np.random.randn(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try using the compiler directives on the `apply_trapez` function to see if there are further performance gains to be had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try using Cython to improve the performance of a gradient descent algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def gradient_descent(x0, f, f_prime, adapt=False):\n",
    "    x_i, y_i = x0\n",
    "    all_x_i = list()\n",
    "    all_y_i = list()\n",
    "    all_f_i = list()\n",
    "\n",
    "    for i in range(1, 100):\n",
    "        all_x_i.append(x_i)\n",
    "        all_y_i.append(y_i)\n",
    "        all_f_i.append(f([x_i, y_i]))\n",
    "        dx_i, dy_i = f_prime(np.asarray([x_i, y_i]))\n",
    "        if adapt:\n",
    "            # Compute a step size using a line_search\n",
    "            step = optimize.line_search(f, f_prime,\n",
    "                                np.r_[x_i, y_i], -np.r_[dx_i, dy_i],\n",
    "                                np.r_[dx_i, dy_i], c2=.05)\n",
    "            step = step[0]\n",
    "        else:\n",
    "            step = 1\n",
    "        x_i += -step*dx_i\n",
    "        y_i += -step*dy_i\n",
    "        if np.abs(all_f_i[-1]) < 1e-16:\n",
    "            break\n",
    "    return all_x_i, all_y_i, all_f_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample function to optimize. Recall from Section 3 that it returns both the quadratic function and its gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quad(epsilon, ndim=2):\n",
    "    def f(x):\n",
    "        x = np.asarray(x)\n",
    "        y = x.copy()\n",
    "        y *= np.power(epsilon, np.arange(ndim))\n",
    "        return .33*np.sum(y**2)\n",
    "\n",
    "    def f_prime(x):\n",
    "        x = np.asarray(x)\n",
    "        y = x.copy()\n",
    "        scaling = np.power(epsilon, np.arange(ndim))\n",
    "        y *= scaling\n",
    "        return .33*2*scaling*y\n",
    "\n",
    "    return f, f_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0, y0 = 1.6, 1.1\n",
    "\n",
    "f, f_prime = quad(0.8)\n",
    "%timeit gd_x_i, gd_y_i, gd_f_i = gradient_descent([x0, y0], f, f_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Numba\n",
    "\n",
    "Cython precompiles parts of Python code before running. Another approach is **Just-in-Time (JIT)** compilation. Numba is a compiler that runs Python code through an LLVM compiler to produce optimized bytecode for fast execution. Numba does not require a C/C++ compiler on your machine.\n",
    "\n",
    "Numba's lone API is a **decorator**.\n",
    "\n",
    "The `@jit` decorator runs the decorated function through bytecode analysis and the function arguments through a type inference engine, and generates an intermediate representation of your code, which is then passed to LLVM for compilation to bytecode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import jit, autojit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def nfibonacci(size):\n",
    "    F = np.empty(size, 'int')\n",
    "    a, b = 0, 1\n",
    "    for i in range(size):\n",
    "        F[i] = a\n",
    "        a, b = b, a + b\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfibonacci(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba is able to compile separate specializations depending on the input types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want fine-grained control over types chosen by the compiler, you can tell Numba the function signature (types) to expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import int32\n",
    "\n",
    "@jit(int32[:](int32))\n",
    "def nfibonacci(size):\n",
    "    F = np.empty(size, 'int')\n",
    "    a, b = 0, 1\n",
    "    for i in range(size):\n",
    "        F[i] = a\n",
    "        a, b = b, a + b\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfibonacci(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilation is deferred until the first function execution. Numba will infer the argument types at call time, and generate optimized code based on this information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairwise_python(X):\n",
    "    M = X.shape[0]\n",
    "    N = X.shape[1]\n",
    "    D = np.empty((M, M), dtype=np.float)\n",
    "    for i in range(M):\n",
    "        for j in range(M):\n",
    "            d = 0.0\n",
    "            for k in range(N):\n",
    "                tmp = X[i, k] - X[j, k]\n",
    "                d += tmp * tmp\n",
    "            D[i, j] = np.sqrt(d)\n",
    "    return D\n",
    "\n",
    "X = np.random.random((1000, 3))\n",
    "\n",
    "%timeit pairwise_python(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def npairwise_python(X):\n",
    "    M = X.shape[0]\n",
    "    N = X.shape[1]\n",
    "    D = np.empty((M, M), dtype=np.float)\n",
    "    for i in range(M):\n",
    "        for j in range(M):\n",
    "            d = 0.0\n",
    "            for k in range(N):\n",
    "                tmp = X[i, k] - X[j, k]\n",
    "                d += tmp * tmp\n",
    "            D[i, j] = np.sqrt(d)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit npairwise_python(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba-compiled functions can call other compiled functions. In some situations, the optimizer may even inline the function in the machine code code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "def hypot(x, y):\n",
    "    return np.sqrt(square(x) + square(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit hypot(10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def nsquare(x):\n",
    "    return x ** 2\n",
    "\n",
    "@jit\n",
    "def nhypot(x, y):\n",
    "    return np.sqrt(nsquare(x) + nsquare(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit nhypot(10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba can compile *most* NumPy functions, as well as generators.\n",
    "\n",
    "Numba does *not* compile things like lists, sets, dictionaries (tuples are compiled), comprehensions, and string operations, so there will be no speedup for these.\n",
    "\n",
    "As with all performance tools, the best strategy is not to apply the `@jit` decorator all over your code, but to use Python's profiling tools to identify \"hotspots\" in your program, and selectively apply `@jit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba can also be used to **vectorize** computations, meaning that one does not explictly have to loop over iterables of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize\n",
    "def nsquare_vec(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit nsquare(df.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit nsquare_vec(df.a.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as of pandas 0.20, Numba only works on the underlying array in pandas data structures, and not DataFrames or Series themselves, hence the passing of `.values` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One performance caveat is that Numba will only speed up code that uses NumPy arrays (so-called `nopython` mode). When your code includes things like lists, strings or dictionaries, it will revert to `object` mode and not provide an appreciable speedup to your code. If you wish to have an exception thrown when `object` mode is used, you can apply the following argument to the `jit` decorator:\n",
    "\n",
    "    @jit(nopython=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use Numba to just-in-time compile the trapezoidal integration function we used above. See how it compares with Cython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Augspurger, T. (2016) [Effective Pandas](https://leanpub.com/effective-pandas). Leanpub.\n",
    "\n",
    "van der Plas, J. (2014) [Why Python is Slow: Looking Under the Hood](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/)\n",
    "\n",
    "van der Plas, J. (2015) [Optimizing Python in the Real World: NumPy, Numba, and the NUFFT](https://jakevdp.github.io/blog/2015/02/24/optimizing-python-with-numpy-and-numba/)\n",
    "\n",
    "[A guide to analyzing Python performance](http://www.huyng.com/posts/python-performance-analysis/)\n",
    "\n",
    "[Kurt Smith's Cython tutorial from SciPy 2013](https://www.youtube.com/watch?v=JKCjsRDffXo)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": "2",
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
